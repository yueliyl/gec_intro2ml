{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f7041c7b",
      "metadata": {
        "id": "f7041c7b"
      },
      "source": [
        "# Introduction to Dimensionality Reduction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install umap-learn[plot]"
      ],
      "metadata": {
        "id": "ZnT9VQbHVak1"
      },
      "id": "ZnT9VQbHVak1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30e36797",
      "metadata": {
        "id": "30e36797"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import zscore\n",
        "import pandas as pd\n",
        "from itertools import combinations\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "from seaborn import lmplot, scatterplot\n",
        "import umap\n",
        "import pickle\n",
        "import random\n",
        "from IPython.display import display, clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dfd6c7b",
      "metadata": {
        "id": "2dfd6c7b"
      },
      "source": [
        "# Principal Components Analysis (PCA)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f73b030e",
      "metadata": {
        "id": "f73b030e"
      },
      "source": [
        "With PCA, data from a high-dimensional space (e.g. 2D, a plane) can be projected onto a lower-dimensional space (e.g. 1D, a line).\n",
        "\n",
        "<center><img src=\"https://raw.githubusercontent.com/McGill-MiCM/MiCM2022_Dim_Reduction/main/pca_proj.jpeg\" alt=\"Alt Text\" width=\"600\"></center>\n",
        "<div style=\"text-align: center\"> source: https://programmathically.com/principal-components-analysis-explained-for-dummies/ </div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad360ea4",
      "metadata": {
        "id": "ad360ea4"
      },
      "source": [
        "Here is an example of 3D data projected onto a 2D plane."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42c95f87",
      "metadata": {
        "id": "42c95f87"
      },
      "source": [
        "<center><img src=\"https://raw.githubusercontent.com/McGill-MiCM/MiCM2022_Dim_Reduction/main/pca.png\" width=\"800\"></center>\n",
        "<div style=\"text-align: center\"> source: https://www.publicdomainpictures.net/en/free-download.php?image=shadows-on-the-beach&id=177457 </div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36ceb21f",
      "metadata": {
        "id": "36ceb21f"
      },
      "outputs": [],
      "source": [
        "## Import iris dataset\n",
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "## Store data in pandas DataFrame\n",
        "iris_df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
        "                     columns= iris['feature_names'] + ['target'])\n",
        "\n",
        "## Rename columns\n",
        "iris_df['target'] = iris_df['target'].map({0:iris.target_names[0], 1:iris.target_names[1], 2:iris.target_names[2]})\n",
        "iris_df.rename(columns = {'target':'species'}, inplace=True)\n",
        "\n",
        "## Display data and list species' names\n",
        "display(iris_df)\n",
        "print(iris_df['species'].unique())\n",
        "\n",
        "## Extract numerical values in arrays\n",
        "x = iris_df.iloc[:,:-1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83e9f68a",
      "metadata": {
        "id": "83e9f68a"
      },
      "outputs": [],
      "source": [
        "## Normalize data: zero mean & unit variance\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x = scaler.fit_transform(x)\n",
        "x_trunc = x[:,:-1]  ## first three features, for visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "960c01f0",
      "metadata": {
        "id": "960c01f0"
      },
      "outputs": [],
      "source": [
        "## Compare histograms of features before and after applying the standard scaler\n",
        "\n",
        "iris_df.hist(sharex=True, layout=(1,4), figsize=[12,3])\n",
        "plt.suptitle('Before standardization'); plt.tight_layout(); plt.show()\n",
        "\n",
        "pd.DataFrame(x, columns=iris_df.columns[:-1].str.strip(' (cm)')).hist(sharex=True, layout=(1,4), figsize=[12,3])\n",
        "plt.suptitle('After standardization'); plt.tight_layout(); plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8210735",
      "metadata": {
        "id": "d8210735"
      },
      "outputs": [],
      "source": [
        "## Visualize truncated data containing first three features\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "fig = plt.figure(1, figsize=(6, 4))\n",
        "ax = fig.add_subplot(111, projection=\"3d\", elev=-150, azim=110)\n",
        "\n",
        "ax.scatter(x_trunc[:,0], x_trunc[:,1], x_trunc[:,2]);\n",
        "\n",
        "ax.set_xlabel(iris_df.columns[0]); ax.set_ylabel(iris_df.columns[1]); ax.set_zlabel(iris_df.columns[2])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ad03174",
      "metadata": {
        "id": "1ad03174"
      },
      "outputs": [],
      "source": [
        "## Compare 2D projections of full vs truncated data\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "fig, ax = plt.subplots(1,1,figsize=[6.,6.])\n",
        "ax.set_xlabel('PCA 1'); ax.set_ylabel('PCA 2')\n",
        "ax.set_xticks([]); ax.set_yticks([])\n",
        "\n",
        "## 2D PCA projection of truncated data\n",
        "pca = PCA(n_components=2)\n",
        "x_2d = pca.fit_transform(x_trunc)\n",
        "ax.scatter(x_2d[:,0], x_2d[:,1], label='truncated data\\n(3 features)')\n",
        "\n",
        "## 2D PCA projection of full data\n",
        "pca = PCA(n_components=2)\n",
        "x_2d = pca.fit_transform(x)\n",
        "ax.scatter(x_2d[:,0], x_2d[:,1], label='full data\\n(4 features)')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f12c5ac",
      "metadata": {
        "id": "7f12c5ac"
      },
      "outputs": [],
      "source": [
        "## Show \"manual\" 2D PCA projection alongside PCA weights for different features\n",
        "\n",
        "fig, ax = plt.subplots(1,2,figsize=[12,6])\n",
        "ax[0].set_xlabel('PCA 1')  # proportion of variance explained by PCA component 1\n",
        "ax[0].set_ylabel('PCA 2')  # proportion of variance explained by PCA component 2\n",
        "ax[0].set_xticks([]); ax[0].set_yticks([])\n",
        "ax[0].set_title('PCA projection ($\\hat{X} = XU^T$)')\n",
        "\n",
        "## Matrix multiplication to obtain projection\n",
        "x_2d_manual = x @ pca.components_[:2,:].T\n",
        "ax[0].scatter(x_2d_manual[:,0], x_2d_manual[:,1]);\n",
        "\n",
        "xlim = ax[0].get_xlim()\n",
        "ylim = ax[0].get_ylim()\n",
        "\n",
        "## Barplot of components' weights\n",
        "bp = pd.DataFrame(pca.components_, columns=iris_df.columns[:-1].str.strip(' (cm)'), index=['PCA 1', 'PCA 2']).plot.bar(ax=ax[1], rot=0);\n",
        "\n",
        "bp.set_ylabel('weight');\n",
        "for p in ax[1].patches: ax[1].annotate(str(round(p.get_height(), 2)), (p.get_x()-0.005, p.get_height()*1.025))\n",
        "ax[1].set_title('PCA weights ($U$)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e01d06fe",
      "metadata": {
        "id": "e01d06fe"
      },
      "source": [
        "$$\n",
        "PCA.1 = 0.52 * sepal.length - 0.27 * sepal.width + 0.58 * petal.length + 0.56 * petal.width\\\\\n",
        "PCA.2 = 0.38 * sepal.length + 0.92 * sepal.width + 0.02 * petal.length + 0.07 * petal.width\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c49d3bcd",
      "metadata": {
        "id": "c49d3bcd"
      },
      "source": [
        "Performing a PCA projection amounts to applying the equations above to create PCA variables, which we can plot. In the code below, we will loop through each data point to compute PCA projections using the data features and PCA weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "579e0233",
      "metadata": {
        "id": "579e0233"
      },
      "outputs": [],
      "source": [
        "## Create figure\n",
        "\n",
        "fig = plt.figure(figsize=[3,3])\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.set_xlim(xlim)\n",
        "ax.set_ylim(ylim)\n",
        "ax.set_xlabel('PCA 1')\n",
        "ax.set_ylabel('PCA 2')\n",
        "\n",
        "\n",
        "## Loop through data points\n",
        "for i in range(len(x)):\n",
        "\n",
        "    xi = x[i,:].squeeze()\n",
        "\n",
        "    c1 = pca.components_[0,:]\n",
        "    c2 = pca.components_[1,:]\n",
        "\n",
        "    xi_pc1 = (xi * c1).sum()\n",
        "    xi_pc2 = (xi * c2).sum()\n",
        "    ax.scatter(xi_pc1, xi_pc2, c='grey')\n",
        "\n",
        "    dpi = 'Data point ' + str(i)\n",
        "    pc1_1 = '({:.2f})*({:.2f})'.format(c1[0] , xi[0])\n",
        "    pc1_2 = '({:.2f})*({:.2f})'.format(c1[1] , xi[1])\n",
        "    pc1_3 = '({:.2f})*({:.2f})'.format(c1[2] , xi[2])\n",
        "    pc1_4 = '({:.2f})*({:.2f})'.format(c1[3] , xi[3])\n",
        "\n",
        "    pc2_1 = '({:.2f})*({:.2f})'.format(c2[0] , xi[0])\n",
        "    pc2_2 = '({:.2f})*({:.2f})'.format(c2[1] , xi[1])\n",
        "    pc2_3 = '({:.2f})*({:.2f})'.format(c2[2] , xi[2])\n",
        "    pc2_4 = '({:.2f})*({:.2f})'.format(c2[3] , xi[3])\n",
        "\n",
        "    pc_info = str(\n",
        "    '''\n",
        "    {:<16}: {:>15}    {:>15}    {:>15}    {:>15}\n",
        "    {:<16}: {:>15.2f}    {:>15.2f}    {:>15.2f}    {:>15.2f}\n",
        "    {:<16}: {:>16} + {:>16} + {:>16} + {:>16} = {:>5.2f}\n",
        "    {:<16}: {:>16} + {:>16} + {:>16} + {:>16} = {:>5.2f}\n",
        "    '''.format(\n",
        "    'features', 'sepal length', 'sepal width', 'petal length', 'petal width',\n",
        "    dpi, *xi,\n",
        "    'PCA 1' , pc1_1 , pc1_2 , pc1_3 , pc1_4, xi_pc1,\n",
        "    'PCA 2' , pc2_1 , pc2_2 , pc2_3 , pc2_4, xi_pc2))\n",
        "\n",
        "    display(fig)\n",
        "    print(pc_info)\n",
        "\n",
        "    clear_output(wait = True)\n",
        "    plt.pause(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d10cd0b8",
      "metadata": {
        "id": "d10cd0b8"
      },
      "outputs": [],
      "source": [
        "## Color data points by species\n",
        "\n",
        "iris_df_2d = pd.DataFrame(data = np.c_[x_2d, iris_df['species']], columns=['PCA 1', 'PCA 2', 'species'])\n",
        "lmplot(x='PCA 1', y='PCA 2', data=iris_df_2d, hue='species', fit_reg=False);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e35edcd",
      "metadata": {
        "id": "6e35edcd"
      },
      "outputs": [],
      "source": [
        "## Compute 4 PCA components rather than just 2 components\n",
        "pca_4d = PCA(n_components=4)\n",
        "x_4d = pca_4d.fit_transform(x)\n",
        "\n",
        "## Plot all 6 possible 2D PCA projections\n",
        "p = np.arange(4)\n",
        "pcombs = list(combinations(p,2))\n",
        "\n",
        "plt_cols = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
        "colors = {'setosa':plt_cols[0], 'versicolor':plt_cols[1], 'virginica':plt_cols[2]}\n",
        "\n",
        "_, ax = plt.subplots(2,3, figsize=[15.,10.])\n",
        "for i, pcomb in enumerate(pcombs):\n",
        "    axi = np.unravel_index(i, ax.shape)\n",
        "    ax[axi].scatter(x_4d[:,pcomb[0]], x_4d[:,pcomb[1]], c=iris_df['species'].map(colors))\n",
        "\n",
        "    ax[axi].set_xlabel('PCA ' + str(pcomb[0]+1)); ax[axi].set_ylabel('PCA ' + str(pcomb[1]+1))\n",
        "    ax[axi].set_xticks([]); ax[axi].set_yticks([])\n",
        "\n",
        "\n",
        "## Plot singular values and related quantities\n",
        "fig, ax = plt.subplots(1,4,figsize=[15.,3.])\n",
        "\n",
        "sv_1 = pca_4d.singular_values_\n",
        "sv_2 = pca_4d.singular_values_**2\n",
        "sv_3 = pca_4d.singular_values_**2 / (pca_4d.singular_values_**2).sum()\n",
        "sv_4 = pca_4d.explained_variance_ratio_\n",
        "\n",
        "pd.DataFrame(sv_1, index=['PCA 1', 'PCA 2', 'PCA 3', 'PCA 4']).plot.bar(ax=ax[0], rot=0, legend=False, color='cyan', title='singular values');\n",
        "for p in ax[0].patches: ax[0].annotate(str(round(p.get_height(), 2)), (p.get_x()+0.01, p.get_height()*0.9))\n",
        "pd.DataFrame(sv_2, index=['PCA 1', 'PCA 2', 'PCA 3', 'PCA 4']).plot.bar(ax=ax[1], rot=0, legend=False, color='cyan', title='squared singular values');\n",
        "for p in ax[1].patches: ax[1].annotate(str(round(p.get_height(), 2)), (p.get_x()+0.01, p.get_height()*0.9))\n",
        "pd.DataFrame(sv_3, index=['PCA 1', 'PCA 2', 'PCA 3', 'PCA 4']).plot.bar(ax=ax[2], rot=0, legend=False, color='cyan', title='ratio of squared sing. values');\n",
        "for p in ax[2].patches: ax[2].annotate(str(round(p.get_height(), 2)), (p.get_x()+0.01, p.get_height()*0.9))\n",
        "pd.DataFrame(sv_4, index=['PCA 1', 'PCA 2', 'PCA 3', 'PCA 4']).plot.bar(ax=ax[3], rot=0, legend=False, color='cyan', title='variance explained');\n",
        "for p in ax[3].patches: ax[3].annotate(str(round(p.get_height(), 2)), (p.get_x()+0.01, p.get_height()*0.9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9b79418",
      "metadata": {
        "id": "f9b79418"
      },
      "outputs": [],
      "source": [
        "## Plot cumulative sum of variances explained by the PCA components\n",
        "\n",
        "_, ax = plt.subplots(1,1)\n",
        "pd.DataFrame(sv_4.cumsum(), index=['PCA 1', 'PCA 2', 'PCA 3', 'PCA 4']).plot.bar(ax=ax, rot=0, legend=False, color='cyan', title='variance explained');\n",
        "for p in ax.patches: ax.annotate(str(round(p.get_height(), 2)), (p.get_x()+0.1, p.get_height()*0.9))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-means"
      ],
      "metadata": {
        "id": "10h3n3g81moj"
      },
      "id": "10h3n3g81moj"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "pca = PCA(n_components=2).fit(x)\n",
        "x_2d = pca.transform(x)\n",
        "\n",
        "kmeans = KMeans(n_clusters=3, n_init=1).fit(x_2d)"
      ],
      "metadata": {
        "id": "eOwGwVjDCOMP"
      },
      "id": "eOwGwVjDCOMP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step size of the mesh. Decrease to increase the quality of the VQ.\n",
        "h = 0.02  # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
        "\n",
        "# Plot the decision boundary. For that, we will assign a color to each\n",
        "x_min, x_max = x_2d[:, 0].min() - 1, x_2d[:, 0].max() + 1\n",
        "y_min, y_max = x_2d[:, 1].min() - 1, x_2d[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "\n",
        "# Obtain labels for each point in mesh. Use last trained model.\n",
        "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "\n",
        "# Put the result into a color plot\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.figure(1)\n",
        "plt.clf()\n",
        "plt.imshow(\n",
        "    Z,\n",
        "    interpolation=\"nearest\",\n",
        "    extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
        "    cmap=plt.cm.Paired,\n",
        "    aspect=\"auto\",\n",
        "    origin=\"lower\",\n",
        ")\n",
        "\n",
        "plt.plot(x_2d[:, 0], x_2d[:, 1], \"k.\", markersize=2)\n",
        "# Plot the centroids as a white X\n",
        "centroids = kmeans.cluster_centers_\n",
        "plt.scatter(\n",
        "    centroids[:, 0],\n",
        "    centroids[:, 1],\n",
        "    marker=\"x\",\n",
        "    s=169,\n",
        "    linewidths=3,\n",
        "    color=\"w\",\n",
        "    zorder=10,\n",
        ")\n",
        "plt.title(\n",
        "    \"K-means clustering on the Iris dataset (PCA-reduced data)\\n\"\n",
        "    \"Centroids are marked with white cross\"\n",
        ")\n",
        "plt.xlim(x_min, x_max)\n",
        "plt.ylim(y_min, y_max)\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RSv7r2ToEwpo"
      },
      "id": "RSv7r2ToEwpo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember: since K-means is an unsupervised clustering algorithm, it is never aware of the labels (i.e. flower types). Nonetheless, K-means is still capable of relating datapoints to flower types in a sensible manner."
      ],
      "metadata": {
        "id": "H2HuZYzoGQMl"
      },
      "id": "H2HuZYzoGQMl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hierarchical Clustering"
      ],
      "metadata": {
        "id": "8ZKVoqvX1p37"
      },
      "id": "8ZKVoqvX1p37"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from scipy.cluster.hierarchy import dendrogram"
      ],
      "metadata": {
        "id": "QdS7c3RAHPfM"
      },
      "id": "QdS7c3RAHPfM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## from sklearn tutorial\n",
        "def plot_dendrogram(model, **kwargs):\n",
        "\n",
        "    # Create linkage matrix and then plot the dendrogram\n",
        "\n",
        "    # create the counts of samples under each node\n",
        "    counts = np.zeros(model.children_.shape[0])\n",
        "    n_samples = len(model.labels_)\n",
        "    for i, merge in enumerate(model.children_):\n",
        "        current_count = 0\n",
        "        for child_idx in merge:\n",
        "            if child_idx < n_samples:\n",
        "                current_count += 1  # leaf node\n",
        "            else:\n",
        "                current_count += counts[child_idx - n_samples]\n",
        "        counts[i] = current_count\n",
        "\n",
        "    linkage_matrix = np.column_stack(\n",
        "        [model.children_, model.distances_, counts]\n",
        "    ).astype(float)\n",
        "\n",
        "    # Plot the corresponding dendrogram\n",
        "    dendrogram(linkage_matrix, **kwargs)"
      ],
      "metadata": {
        "id": "LiaM1-zSHQYF"
      },
      "id": "LiaM1-zSHQYF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting distance_threshold=0 ensures we compute the full tree.\n",
        "model = AgglomerativeClustering(distance_threshold=0, n_clusters=None).fit(x)\n",
        "\n",
        "# plot dendrogram\n",
        "plt.title(\"Hierarchical Clustering Dendrogram\")\n",
        "plot_dendrogram(model, truncate_mode=\"level\", p=3)\n",
        "plt.xlabel(\"Number of samples in node (or index of point if no parenthesis).\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIrIpjinCOs6"
      },
      "id": "TIrIpjinCOs6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_clusters_list = [len(x), 30, 10, 3]\n",
        "\n",
        "fig, ax = plt.subplots(1,len(n_clusters_list), figsize=[16,4], sharex=True, sharey=True)\n",
        "\n",
        "for nc, n_clusters in enumerate(n_clusters_list):\n",
        "\n",
        "    if n_clusters < len(x):\n",
        "      hierarchical_clustering = AgglomerativeClustering(n_clusters=n_clusters).fit(x)\n",
        "    else:\n",
        "      hierarchical_clustering = AgglomerativeClustering(distance_threshold=0, n_clusters=None).fit(x)\n",
        "\n",
        "    ax[nc].scatter(x_2d[:,0], x_2d[:,1], c=hierarchical_clustering.labels_, cmap='tab20')\n",
        "\n",
        "    ax[nc].set_title(f'{n_clusters} clusters')\n",
        "    ax[nc].set_xlabel('PCA 1'); ax[nc].set_ylabel('PCA 2')\n",
        "    ax[nc].set_xticks([]); ax[nc].set_yticks([])\n",
        "\n",
        "fig.tight_layout(); fig.show()\n",
        "\n",
        "\n",
        "## Plot ground truth\n",
        "plt.figure(figsize=[6,6])\n",
        "iris_df_2d = pd.DataFrame(data = np.c_[x_2d, iris_df['species']], columns=['PCA 1', 'PCA 2', 'species'])\n",
        "lmplot(x='PCA 1', y='PCA 2', data=iris_df_2d, hue='species', fit_reg=False);\n",
        "plt.title('Ground truth')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mpBkBF8gM5xs"
      },
      "id": "mpBkBF8gM5xs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization with tSNE and UMAP"
      ],
      "metadata": {
        "id": "Xv0ALKhzc9D_"
      },
      "id": "Xv0ALKhzc9D_"
    },
    {
      "cell_type": "markdown",
      "id": "8c6a1644",
      "metadata": {
        "id": "8c6a1644"
      },
      "source": [
        "#### MNIST data\n",
        "\n",
        "<center><img src=\"https://raw.githubusercontent.com/McGill-MiCM/MiCM2022_Dim_Reduction/main/mnist.jpeg\" width=\"400\"></center>\n",
        "<div style=\"text-align: center\"> source: https://github.com/cazala/mnist </div>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import umap\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (_, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_train= StandardScaler().fit_transform(x_train)\n",
        "\n",
        "reducer = umap.UMAP()\n",
        "embedding = reducer.fit_transform(x_train)\n",
        "\n",
        "sort_idxs = y_train.argsort()\n",
        "y_train = y_train[sort_idxs]\n",
        "embedding = embedding[sort_idxs]\n",
        "\n",
        "embedding = pd.DataFrame(embedding, columns=['UMAP 1','UMAP 2'])\n",
        "scatterplot(embedding, x='UMAP 1', y='UMAP 2', hue=y_train.astype(str), alpha=0.5)\n",
        "plt.title('UMAP embedding of MNIST digits')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pjFJMI_adESn"
      },
      "id": "pjFJMI_adESn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0772f131",
      "metadata": {
        "id": "0772f131"
      },
      "source": [
        "# Autoencoders\n",
        "\n",
        "#### A word about neural networks\n",
        "Neural networks combine linear and non-linear transformations to obtain powerful hidden representations of data. These hidden representations serve many purposes such as regression, classification, probability density estimation, image segmentation, etc.\n",
        "\n",
        "<center><img src=\"https://raw.githubusercontent.com/McGill-MiCM/MiCM2022_Dim_Reduction/main/neuralnet.png\" width=\"400\"></center>\n",
        "<div style=\"text-align: center\"> source: https://en.wikipedia.org/wiki/Neural_network </div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fce3d7a4",
      "metadata": {
        "id": "fce3d7a4"
      },
      "source": [
        "#### Autoencoders\n",
        "\n",
        "Within the context of dimensionality reduction, autoencoders are a subclass of neural networks which contains a hidden layer whose size is *smaller* than that of the input layer. Moreover, the output layer of an autoencoder aims at *reconstructing* the data provided at the input layer.\n",
        "\n",
        "<center><img src=\"https://raw.githubusercontent.com/McGill-MiCM/MiCM2022_Dim_Reduction/main/autoencoder.png\" width=\"700\"></center>\n",
        "<div style=\"text-align: center\"> source: https://www.jeremyjordan.me/autoencoders/ </div>\n",
        "\n",
        "One can analyse the learned variables contained within the hidden layer. In this way, we achieve dimensionality reduction since these hidden variables are smaller in number than the original input variables."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34604ab2",
      "metadata": {
        "id": "34604ab2"
      },
      "source": [
        "#### Variational Autoencoders\n",
        "\n",
        "We've briefly discussed how PCA can be framed within a probabilistic setting, leading to Probabilistic PCA. Similarly, **variational autoencoders** (VAE) frame the autoencoder framework within a probabilistic setting. Rather than estimate hidden variables within the bottleneck layer, VAEs estimate *hidden probability distributions* from which hidden variables can be sampled from.\n",
        "\n",
        "<center><img src=\"https://raw.githubusercontent.com/McGill-MiCM/MiCM2022_Dim_Reduction/main/vae.png\" width=\"700\"></center>\n",
        "<div style=\"text-align: center\"> source: https://www.jeremyjordan.me/autoencoders/ </div>\n",
        "\n",
        "These hidden probability distributions are often chosen to follow the Gaussian/Normal distribution. This design provides structure to the bottleneck layer while also accounting for variability which is inherent within the data. Defining probability distributions within the bottleneck layer also has interesting implications for data generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98170d3b",
      "metadata": {
        "id": "98170d3b"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0c398b1",
      "metadata": {
        "id": "e0c398b1"
      },
      "source": [
        "**Note**: exercises adapted from: https://www.theaidream.com/post/an-introduction-to-autoencoder-and-variational-autoencoder-vae"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2163369",
      "metadata": {
        "id": "b2163369"
      },
      "source": [
        "#### Construct and train autoencoder model\n",
        "\n",
        "**Note**: There are three hidden layers in this model, where the middle bottleneck layer is called the *encoding* layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38d19162",
      "metadata": {
        "id": "38d19162"
      },
      "outputs": [],
      "source": [
        "# This is the size of our encoded representations\n",
        "encoding_dim = 2\n",
        "\n",
        "hidden_dim = 64\n",
        "\n",
        "# This is our input image\n",
        "input_img = keras.Input(shape=(784,))\n",
        "\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "hidden_enc = layers.Dense(hidden_dim, activation='relu')(input_img)\n",
        "encoded = layers.Dense(encoding_dim, activation='relu')(hidden_enc)\n",
        "ae_encoder = keras.Model(input_img, encoded, name='encoder')\n",
        "\n",
        "# \"decoded\" is the lossy reconstruction of the input\n",
        "encoded_inputs = keras.Input(shape=(encoding_dim,), name='z_sampling')\n",
        "hidden_dec = layers.Dense(hidden_dim, activation='relu')(encoded_inputs)\n",
        "decoded = layers.Dense(784, activation='sigmoid')(hidden_dec)\n",
        "ae_decoder = keras.Model(encoded_inputs, decoded, name='decoder')\n",
        "\n",
        "output_img = ae_decoder(ae_encoder(input_img))\n",
        "\n",
        "autoencoder = keras.Model(input_img, output_img, name='ae')\n",
        "\n",
        "#Now let's train our autoencoder to reconstruct MNIST digits.\n",
        "#First, we'll configure our model to use a per-pixel binary crossentropy loss, and the Adam optimizer:\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "#Let's prepare our input data. We're using MNIST digits, and we're discarding the labels (since we're only interested in encoding/decoding the input images).\n",
        "(x_train, _), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "#We will normalize all values between 0 and 1 and we will flatten the 28x28 images into vectors of size 784.\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "\n",
        "#Now let's train our autoencoder for 50 epochs:\n",
        "ae_history = autoencoder.fit(x_train, x_train,\n",
        "                epochs=10,\n",
        "                batch_size=32,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))\n",
        "\n",
        "print('Final train loss and validation loss: {:.3f} and {:.3f}'.format(ae_history.history['loss'][-1], ae_history.history['val_loss'][-1]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "270d9cc1",
      "metadata": {
        "id": "270d9cc1"
      },
      "outputs": [],
      "source": [
        "## Encode and decode some digits\n",
        "\n",
        "n = 10  # Number of digits to display\n",
        "\n",
        "encoded_imgs = ae_encoder.predict(x_test, verbose=0)\n",
        "decoded_imgs = ae_decoder.predict(encoded_imgs, verbose=0)\n",
        "\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82d1d56a",
      "metadata": {
        "id": "82d1d56a"
      },
      "outputs": [],
      "source": [
        "## Plot MNIST samples in bottleneck layer of autoencoder model\n",
        "\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "\n",
        "x_test_encoded = ae_encoder.predict(x_test, verbose=0)\n",
        "\n",
        "plt.figure(figsize=(7, 6))\n",
        "plt.scatter(x_test_encoded[:,0], x_test_encoded[:,1], c=y_test, cmap='tab10')\n",
        "plt.xlabel('autoencoder 1')\n",
        "plt.ylabel('autoencoder 2')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10614734",
      "metadata": {
        "id": "10614734"
      },
      "outputs": [],
      "source": [
        "## Display a 2D manifold of the digits\n",
        "\n",
        "n = 15  # figure with 15x15 digits\n",
        "digit_size = 28\n",
        "figure = np.zeros((digit_size * n, digit_size * n))\n",
        "\n",
        "# We will sample n points\n",
        "grid_x = np.flip(np.linspace(0, 120, n))\n",
        "grid_y = np.linspace(0, 100, n)\n",
        "\n",
        "# Apply AE decoder along grid pattern\n",
        "for i, yi in enumerate(grid_x):\n",
        "    for j, xi in enumerate(grid_y):\n",
        "        z_sample = np.array([[xi, yi]])\n",
        "        x_decoded = ae_decoder.predict(z_sample, verbose=0)  # decoder\n",
        "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "        figure[i * digit_size: (i + 1) * digit_size,\n",
        "               j * digit_size: (j + 1) * digit_size] = digit\n",
        "\n",
        "fig, ax = plt.subplots(1,1,figsize=(10, 10))\n",
        "ax.imshow(figure)\n",
        "\n",
        "ax.set_xticks( ticks=ax.get_xticks()[1:-1] , labels=np.linspace( grid_x[-1] , grid_x[0] , len(ax.get_xticks()[1:-1]) ))\n",
        "ax.set_yticks( ticks=ax.get_yticks()[1:-1] , labels=np.linspace( grid_y[-1] , grid_y[0] , len(ax.get_yticks()[1:-1]) ))\n",
        "\n",
        "ax.set_xlabel('autoencoder 1')\n",
        "ax.set_ylabel('autoencoder 2')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cc01fe3",
      "metadata": {
        "id": "7cc01fe3"
      },
      "source": [
        "#### Construct and train variational autoencoder model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c267f3bf",
      "metadata": {
        "id": "c267f3bf"
      },
      "outputs": [],
      "source": [
        "#First, here's our encoder network, mapping inputs to our latent distribution parameters:\n",
        "\n",
        "latent_dim = 2\n",
        "\n",
        "original_dim = 28 * 28\n",
        "intermediate_dim = 64\n",
        "\n",
        "inputs = keras.Input(shape=(original_dim,))\n",
        "h = layers.Dense(intermediate_dim, activation='relu')(inputs)\n",
        "z_mean = layers.Dense(latent_dim)(h)\n",
        "z_log_sigma = layers.Dense(latent_dim)(h)\n",
        "\n",
        "#We can use these parameters to sample new similar points from the latent space:\n",
        "from keras import backend as K\n",
        "\n",
        "def sampling(args):\n",
        "    z_mean, z_log_sigma = args\n",
        "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=0.1)\n",
        "    return z_mean + K.exp(z_log_sigma) * epsilon\n",
        "\n",
        "z = layers.Lambda(sampling)([z_mean, z_log_sigma])\n",
        "\n",
        "#Finally, we can map these sampled latent points back to reconstructed inputs:\n",
        "# Create encoder\n",
        "vae_encoder = keras.Model(inputs, [z_mean, z_log_sigma, z], name='encoder')\n",
        "\n",
        "# Create decoder\n",
        "latent_inputs = keras.Input(shape=(latent_dim,), name='z_sampling')\n",
        "x = layers.Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
        "outputs = layers.Dense(original_dim, activation='sigmoid')(x)\n",
        "\n",
        "vae_decoder = keras.Model(latent_inputs, outputs, name='decoder')\n",
        "\n",
        "# Instantiate VAE model\n",
        "outputs = vae_decoder(vae_encoder(inputs)[2])\n",
        "\n",
        "vae = keras.Model(inputs, outputs, name='vae_mlp')\n",
        "\n",
        "#We train the model using the end-to-end model, with a custom loss function: the sum of a reconstruction term, and the KL divergence regularization term.\n",
        "\n",
        "reconstruction_loss = keras.losses.binary_crossentropy(inputs, outputs)\n",
        "reconstruction_loss *= original_dim\n",
        "kl_loss = 1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma)\n",
        "kl_loss = K.sum(kl_loss, axis=-1)\n",
        "kl_loss *= -0.5\n",
        "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "vae.add_loss(vae_loss)\n",
        "\n",
        "vae.compile(optimizer='adam')\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "\n",
        "\n",
        "#We train our VAE on MNIST digits:\n",
        "vae_history = vae.fit(x_train, x_train,\n",
        "        epochs=10,\n",
        "        batch_size=32,\n",
        "        validation_data=(x_test, x_test))\n",
        "\n",
        "print('Final train loss and validation loss: {:.3f} and {:.3f}'.format(vae_history.history['loss'][-1], vae_history.history['val_loss'][-1]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Encode and decode some digits\n",
        "\n",
        "x_test_encoded = vae_encoder.predict(x_test, verbose=0)\n",
        "x_test_encoded = x_test_encoded[0]\n",
        "\n",
        "fig, ax = plt.subplots(1,2,figsize=(14, 6))\n",
        "\n",
        "scatter = ax[0].scatter(x_test_encoded[:,0], x_test_encoded[:,1], c=y_test, cmap='tab10', alpha=0.7)\n",
        "ax[0].set_xlabel('variational autoencoder 1')\n",
        "ax[0].set_ylabel('variational autoencoder 2')\n",
        "plt.colorbar(scatter, ax=ax[0])\n",
        "#ax[0].set_colorbar()\n",
        "\n",
        "\n",
        "## Display a 2D manifold of the digits\n",
        "\n",
        "n = 15  # figure with 15x15 digits\n",
        "digit_size = 28\n",
        "figure = np.zeros((digit_size * n, digit_size * n))\n",
        "\n",
        "# We will sample n points within [-15, 15]\n",
        "grid_x = np.flip(np.linspace(-3, 3, n))\n",
        "grid_y = np.linspace(-3, 3, n)\n",
        "\n",
        "# Apply VAE decoder along grid pattern\n",
        "for i, yi in enumerate(grid_x):\n",
        "    for j, xi in enumerate(grid_y):\n",
        "        z_sample = np.array([[xi, yi]])\n",
        "        x_decoded = vae_decoder.predict(z_sample, verbose=0)\n",
        "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "        figure[i * digit_size: (i + 1) * digit_size,\n",
        "               j * digit_size: (j + 1) * digit_size] = digit\n",
        "\n",
        "ax[1].imshow(figure)\n",
        "\n",
        "ax[1].set_xticks( ticks=ax[1].get_xticks()[1:-1] , labels=np.linspace( grid_x[-1] , grid_x[0] , len(ax[1].get_xticks()[1:-1]) ))\n",
        "ax[1].set_yticks( ticks=ax[1].get_yticks()[1:-1] , labels=np.linspace( grid_y[-1] , grid_y[0] , len(ax[1].get_yticks()[1:-1]) ))\n",
        "\n",
        "ax[1].set_xlabel('variational autoencoder 1')\n",
        "ax[1].set_ylabel('variational autoencoder 2')\n",
        "\n",
        "plt.tight_layout(); plt.show()"
      ],
      "metadata": {
        "id": "aofLTD-N-d9T"
      },
      "id": "aofLTD-N-d9T",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dimred_py",
      "language": "python",
      "name": "dimred_py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}